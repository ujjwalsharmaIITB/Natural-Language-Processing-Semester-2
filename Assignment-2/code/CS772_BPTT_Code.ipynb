{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencies\n",
        "\n"
      ],
      "metadata": {
        "id": "f58RVPy6x8Fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Installing dependencies - Run if needed\n",
        "\n",
        "!pip install numpy==1.25.2\n",
        "!pip install tqdm==4.66.2\n",
        "!pip install scikit-learn==1.2.2\n",
        "!pip install spacy==3.7.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPfJsH2hyB5G",
        "outputId": "5ffb0703-b46e-4381-a206-6b2ced36f7b2"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.25.2 in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: tqdm==4.66.2 in /usr/local/lib/python3.10/dist-packages (4.66.2)\n",
            "Requirement already satisfied: scikit-learn==1.2.2 in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2) (3.4.0)\n",
            "Requirement already satisfied: spacy==3.7.4 in /usr/local/lib/python3.10/dist-packages (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (2.6.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.4) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.4) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.4) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.4) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.4) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.4) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.4) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.4) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy==3.7.4) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy==3.7.4) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy==3.7.4) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy==3.7.4) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy==3.7.4) (2.1.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "gFS-1zrGk6Vq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "\n",
        "def one_hot(n): #one-hot encodes the [1,2,3,4] pos tags\n",
        "  z = np.zeros(4)\n",
        "  if n > 0 and n < 5:\n",
        "    z[n-1] = 1\n",
        "  return z\n",
        "\n",
        "def input(sent,n):  #prepares the input_vector. Start token = 1 if starting word, else 0. If Start token 1, next 4 entries are zero since no previous word. If start token 0, next 4 tokens = previous word pos tag and then the 4 after = current word pos tag.\n",
        "  if n == 0:\n",
        "    start = np.array([1])\n",
        "    prev = one_hot(-1)\n",
        "  else:\n",
        "    start = np.array([0])\n",
        "    prev = one_hot(sent[n-1])\n",
        "\n",
        "  x = np.concatenate((start,prev,one_hot(sent[n])))\n",
        "  return x\n",
        "\n",
        "def dataloader(file): #Just write the filename in place of file and it will load the data (you have to upload them to colab first) There are two files -train and test\n",
        "  data = []\n",
        "  with open(file) as json_file:\n",
        "      for row in json_file:\n",
        "        data.append(json.loads(row))\n",
        "  X = []\n",
        "  y = []\n",
        "  for k in range(len(data)):\n",
        "    for i in range(len(data[k]['tokens'])):\n",
        "      X.append(input(data[k]['pos_tags'],i))\n",
        "      y.append(np.array([data[k]['chunk_tags'][i]]))\n",
        "  X = np.array(X)\n",
        "  y = np.array(y)\n",
        "\n",
        "  return X,y"
      ],
      "metadata": {
        "id": "jRAUibVwoFAm"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load train data\n",
        "X_train, y_train = dataloader(\"train.jsonl\")\n",
        "\n",
        "# Load test data\n",
        "X_test, y_test = dataloader(\"test.jsonl\")\n"
      ],
      "metadata": {
        "id": "FeQ-TotOjS8B"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLtFChS_0vfG",
        "outputId": "b1049257-7b85-41ea-d92f-3ad58f4f11c4"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [1],\n",
              "       ...,\n",
              "       [0],\n",
              "       [0],\n",
              "       [0]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recurrent Perceptron"
      ],
      "metadata": {
        "id": "z4w4dp7lk2sP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recurrent Perceptron class"
      ],
      "metadata": {
        "id": "o9SavqzEQSrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "cj8PhRyus9Wt"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "#Instead of perceptron, I'm using a sigmoid (Maybe we can make the curve steeper)\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "  return sigmoid(x)*(1-sigmoid(x))\n",
        "\n",
        "def code_tag(tag):\n",
        "  if tag.lower() == \"noun\":\n",
        "    return 1\n",
        "  elif tag.lower() == \"det\":\n",
        "    return 2\n",
        "  elif tag.lower() == \"adj\":\n",
        "    return 3\n",
        "  else:\n",
        "    return 4\n",
        "\n",
        "\n",
        "class RecurrentPerceptron:\n",
        "  def __init__(self, input_dim):  #input_dim = 9 and T is the number of steps after which weights get updated\n",
        "\n",
        "    #Model Parameters\n",
        "\n",
        "    self.W = np.random.randn(input_dim + 1) # Combine input and recurrent weights\n",
        "    self.hidden_state = np.zeros(1)  # Initialize hidden state\n",
        "    self.b = np.random.uniform(-1,1,1) #Initialise bias\n",
        "    self.T = 3 #number of iterations before BPTT\n",
        "\n",
        "\n",
        "  def forward_backward_pass(self,x,y,learning_rate):\n",
        "    x = x.reshape((9))\n",
        "    y = y.reshape((1))\n",
        "\n",
        "\n",
        "    phi = []            #To store the hidden_state values as we forward pass\n",
        "    phi_prime = []      #To store the derivate values as we forward pass\n",
        "\n",
        "    for iterations in range(self.T):\n",
        "\n",
        "      combined = np.concatenate((x, self.hidden_state))\n",
        "      self.hidden_state = np.array(sigmoid(self.W @ combined - self.b))  # Calculate hidden state with feedback , @ is np.dot\n",
        "\n",
        "      #Store hidden state and derivate values\n",
        "\n",
        "      phi.append(self.hidden_state)\n",
        "      phi_prime.append(np.array([sigmoid_derivative(self.W @ combined - self.b)]))\n",
        "\n",
        "\n",
        "    approximation_length = 2  #Recurring gradients explode; approximation length = Till how long back should we consider\n",
        "\n",
        "\n",
        "    #Complicated product and sum expression to calculate gradient. Pls try to modify/verify this.\n",
        "\n",
        "    s = 0\n",
        "    sh = 0\n",
        "    check = 0\n",
        "    for l in range(approximation_length):\n",
        "      check = 1\n",
        "      p = 1\n",
        "      for k in range(1,l+2):\n",
        "        p *= phi_prime[-k] # approximation - product term for last k gradients\n",
        "      p *= self.W[-1]**l\n",
        "      ph = p*phi[-(l+1)]\n",
        "      s += p\n",
        "      sh += ph\n",
        "    if check != 1:\n",
        "      s = 1\n",
        "      sh = 1\n",
        "\n",
        "    gradient_x = s*x*(self.hidden_state - y)                #gradient corresponding to input_weights\n",
        "    gradient_h = np.array(sh*(self.hidden_state - y))       #gradient corresponding to hidden_weight\n",
        "    gradient = np.concatenate((gradient_x, gradient_h), axis = 1) #concatenating to make one set of weights\n",
        "    gradient_b = -s*(self.hidden_state - y)                  #gradient for bias term\n",
        "\n",
        "    gradient = gradient.reshape(10)\n",
        "    gradient_b = gradient_b.reshape(1)\n",
        "\n",
        "    #print(gradient.shape, self.W.shape)\n",
        "\n",
        "    #Calculate the Gradient\n",
        "    self.W += -learning_rate*gradient       #Weight update\n",
        "    self.b += -learning_rate*gradient_b     #Bias update\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def custom_test(self,sent):\n",
        "    doc = nlp(sent)\n",
        "    pos_tags = []\n",
        "    for token in doc:\n",
        "      pos_tags.append(code_tag(token.pos_))\n",
        "    chunk_tags = []\n",
        "    for n in range(len(pos_tags)):\n",
        "      c = sigmoid(np.dot(self.W[:9],input(pos_tags,n)) - self.b)\n",
        "      if c > 0.5:\n",
        "        chunk_tags.append(1)\n",
        "      else:\n",
        "        chunk_tags.append(0)\n",
        "    return chunk_tags\n",
        "  #Function to evaluate model on a test case\n",
        "\n",
        "  def evaluate(self,x,y):\n",
        "    c = sigmoid(np.dot(self.W[:9],x) - self.b)\n",
        "    y = y[0]\n",
        "    if c>0.5:\n",
        "      yp = 1\n",
        "    else:\n",
        "      yp = 0\n",
        "    return int(yp == y)\n",
        "  def predict(self,x):\n",
        "    c = sigmoid(np.dot(self.W[:9],x) - self.b)\n",
        "    if c>0.5:\n",
        "      yp = 1\n",
        "    else:\n",
        "      yp = 0\n",
        "    return int(yp)"
      ],
      "metadata": {
        "id": "Wtx8pDGev-_W"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialising Model"
      ],
      "metadata": {
        "id": "zCGSLuz1QXjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RecurrentPerceptron(9)"
      ],
      "metadata": {
        "id": "lUXwEFs05PqT"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Randomize the Training set"
      ],
      "metadata": {
        "id": "1k2AIwGvBA5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "indices = np.arange(len(X_train))\n",
        "np.random.shuffle(indices)\n",
        "X_train = X_train[indices]\n",
        "y_train = y_train[indices]"
      ],
      "metadata": {
        "id": "w8nSLZb1_u1g"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFbhb6ri0Wzg",
        "outputId": "708dc558-ddac-4264-d27c-5a3af6b1e15c"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 1., 0., 0., 0., 1., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5-Fold Cross-validation"
      ],
      "metadata": {
        "id": "2oxqEBwCpCjC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from tqdm import tqdm\n",
        "\n",
        "X_combined = X_train\n",
        "y_combined = y_train\n",
        "\n",
        "num_folds = 5\n",
        "\n",
        "kf = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "fold_accuracies = []\n",
        "fold_weights = []\n",
        "fold_biases = []\n",
        "for train_index, test_index in tqdm(kf.split(X_combined)):\n",
        "    X_train_fold, X_test_fold = X_combined[train_index], X_combined[test_index]\n",
        "    y_train_fold, y_test_fold = y_combined[train_index], y_combined[test_index]\n",
        "\n",
        "    model = RecurrentPerceptron(9)\n",
        "    lr = 0.2\n",
        "    for index in range(len(X_train_fold)):\n",
        "        x = X_train_fold[index]\n",
        "        y = y_train_fold[index]\n",
        "        for iterations in range(2):\n",
        "            model.forward_backward_pass(x, y, lr)\n",
        "        s = 0\n",
        "    count = 0\n",
        "    for k in range(len(X_test_fold)):\n",
        "        s += (model.evaluate(X_test_fold[k], y_test_fold[k]))\n",
        "        count += 1\n",
        "    acc = s / count\n",
        "    print(acc)\n",
        "    fold_accuracies.append(acc)\n",
        "    fold_weights.append(model.W)\n",
        "    fold_biases.append(model.b)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvFoH4TDbLSl",
        "outputId": "62a8eac3-63fa-4476-a458-450544bdbaf1"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1it [01:00, 60.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8676243093922652\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r2it [01:50, 54.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8720901679599253\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r3it [02:40, 52.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8685050584421963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r4it [03:30, 51.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8686032806207642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5it [04:21, 52.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8667616147726157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k=0\n",
        "for i in fold_accuracies:\n",
        "  k=k+i\n",
        "k=k/5\n",
        "print(\"Average Validation Accuracy:\",k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fl_s5cyKtsfb",
        "outputId": "257112c7-6ab1-46a3-ebc3-b71a9ded9b5c"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Validation Accuracy: 0.8687168862375533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "fNPBcxcGvXwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sum1=0\n",
        "for i in range(len(X_test)):\n",
        "  sum1+=model.evaluate(X_test[i],y_test[i])\n",
        "sum1=sum1/(len(X_test))\n",
        "print(\"Average Test Accuracy: \",sum1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8G-VkrgoQ5Q",
        "outputId": "40511f7e-52fb-45e2-e95f-2bafa5558f51"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Test Accuracy:  0.8432217077635404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Model Weights: \", model.W)\n",
        "print(\"Model Bias: \", model.b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cN8OoWUtpYnb",
        "outputId": "c6b60bee-0c48-4d27-ac97-9267916d1e10"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Weights:  [ 4.81146369 -1.17227551 -2.83675876 -1.99949326  1.93795498 -2.27467441\n",
            "  1.78531753 -1.78730754  1.76653001  0.61202212]\n",
            "Model Bias:  [-1.10140594]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.custom_test(\"The quick brown fox jumped over the lazy dog.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXG_ZR_PJkak",
        "outputId": "378c085d-0efd-4d03-db90-904a673f582e"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 0, 0, 0, 1, 1, 1, 0, 0, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    }
  ]
}